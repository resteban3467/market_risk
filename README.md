# Optimizaci贸n de Portafolio (ML)

## Resumen del Proyecto 
Este proyecto desarrolla un sistema cuantitativo de principio a fin para la optimizaci贸n de un portafolio de m煤ltiples activos (20 acciones y bonos del tesoro). El sistema integra la **Teor铆a Moderna de Portafolios** con un modelo de **Machine Learning** (XGBRegressor) para ajustar la estrategia de inversi贸n de forma din谩mica, adapt谩ndose al riesgo de mercado predicho.

El flujo de trabajo se divide en dos fases principales, encapsuladas en dos notebooks:
1.  **Obtenci贸n y Almacenamiento de Datos:** Se crea un pipeline de datos robusto para extraer informaci贸n de activos desde APIs p煤blicas ("finance, FRED) y almacenarlos en una base de datos relacional (**PostgreSQL**).
2.  **Optimizaci贸n y Modelado de Riesgo:** Se utiliza la data para construir una **Frontera Eficiente** mediante simulaci贸n de Monte Carlo, calcular m茅tricas de riesgo clave (**VaR**, **Ratio de Sortino**) y entrenar un modelo para predecir la volatilidad futura, permitiendo una selecci贸n estrat茅gica y automatizada del portafolio.

!["Frontera Eficiente"](./fig/frontera_eficiente.png)

---
##  Stack Tecnol贸gico
* **Lenguajes:** Python, SQL (PostgreSQL)
* **Librer铆as de Datos:** Pandas, NumPy
* **ETL y APIs:** yfinance, fredapi, SQLAlchemy
* **Machine Learning:** Scikit-learn, XGBoost
* **Optimizaci贸n de Hiperpar谩metros:** Optuna
* **Explicabilidad:** SHAP
* **Visualizaci贸n:** Plotly, Matplotlib, Seaborn, Kaleido
* **Entorno:** Jupyter Lab, GitHub

---
## Estructura y Metodolog铆a del Proyecto
El repositorio est谩 organizado en dos notebooks que cubren todo el ciclo de vida del proyecto:

### 1. obtener_datos.ipynb (Pipeline de Datos - ETL)
Este notebook se encarga de la extracci贸n, transformaci贸n y carga de los datos.
* **Extracci贸n:** Descarga de precios hist贸ricos de 20 acciones (yfinance) y tasas de bonos del tesoro (FRED API).
* **Transformaci贸n:** Limpieza y reestructuraci贸n de los datos a un formato "largo" para un almacenamiento flexible y escalable.
* **Carga:** Creaci贸n de tablas (datos_acciones, datos_bonos) en una base de datos PostgreSQL y carga de los datos procesados, asegurando la integridad y persistencia de la informaci贸n.

### 2. opt_riesgo.ipynb (An谩lisis, Optimizaci贸n y Modelado)
Este notebook es el n煤cleo del an谩lisis cuantitativo y de Machine Learning.
* **Ingenier铆a de Caracter铆sticas en SQL:** Carga de datos desde PostgreSQL usando una query SQL que pivota las tablas a un formato "ancho" y calcula features como retornos diarios.
* **Optimizaci贸n de Portafolio:**
    * Ejecuci贸n de una **simulaci贸n de Monte Carlo** (+10,000 iteraciones) para generar un universo de portafolios posibles.
    * C谩lculo de m茅tricas de riesgo y rendimiento para cada portafolio, incluyendo **VaR Hist贸rico**, **Ratio de Sharpe**, **Ratio de Sortino** y **Ratio de Calmar** (retorno vs. m谩xima ca铆da).
    * Identificaci贸n de los portafolios de **M铆nima Volatilidad** y **M谩ximo Ratio de Sortino**.
    * Visualizaci贸n interactiva de la **Frontera Eficiente** con Plotly.
* **Modelado de Riesgo con Machine Learning:**
    * Entrenamiento de un XGBRegressor para predecir la volatilidad futura del mercado (usando 'SPY' como proxy).
    * Optimizaci贸n de hiperpar谩metros del modelo con Optuna para minimizar el error de predicci贸n.
    * Interpretaci贸n de las predicciones con **SHAP** para entender qu茅 factores (volatilidad pasada, retornos, etc.) impulsan la volatilidad del mercado.
* **Estrategia Din谩mica:** El sistema utiliza la predicci贸n del modelo de ML para recomendar una estrategia: adoptar el portafolio de **M铆nima Volatilidad** en periodos de alto riesgo predicho, o el de **M谩ximo Ratio de Sortino** en periodos de bajo riesgo.

!["Gr谩fico de Barras"](./fig/shap_importancia.png)

---
## C贸mo Ejecutar el Proyecto

1.  **Clonar el repositorio:**
    ```bash
    git clone [https://github.com/resteban3467/market_risk]
    cd [market_risk]
    ```
2.  **Crear un entorno virtual e instalar dependencias:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # En Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```
3.  **Configurar credenciales:**
    * Crea un archivo ".env" en la ra铆z del proyecto.
    * Pobla el archivo con tus credenciales de **PostgreSQL** y tu clave para la **FRED API**:
        ```
        DB_HOST=localhost
        DB_PORT=5432
        DB_NAME=portfolio_db
        DB_USER=tu_usuario
        DB_PASSWORD=tu_contrase帽a
        FRED_API_KEY=tu_clave_fred_api
        ```
4.  **Ejecutar los notebooks:** Abre Jupyter Lab (jupyter lab) y ejecuta los notebooks en el siguiente orden:
    1.  obtener_datos.ipynb
    2.  opt_riesgo.ipynb

---
## Autor
* **[Esteban Rojas]**
* **LinkedIn:** https://www.linkedin.com/in/esteban-rojas-millar/
* **Email:** [resteban3467@gmail.com]